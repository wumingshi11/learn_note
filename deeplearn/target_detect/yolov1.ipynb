{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv1\n",
    "本文主要介绍YOLOv1的关键实现，只有部分代码。全部代码看源代码。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主干部分\n",
    "YOLOv1主干部分为一个多层的卷积神经网络，使用残差，vgg,都可以，卷积网络输出一个13*13的多通道特征图。供后续使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 颈部网络\n",
    "颈部网络用于对特征图进一步处理，如拼接不同大小的卷积核运算后的特征图，用于后续分类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "# Spatial Pyramid Pooling\n",
    "class SPPF(nn.Module):\n",
    "    \"\"\"\n",
    "        该代码参考YOLOv5的官方代码实现 https://github.com/ultralytics/yolov5\n",
    "        1. 改变输入维度和输出维度\n",
    "        2. 中间通过最大池化层下采样，获取更多信息\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, out_dim, expand_ratio=0.5, pooling_size=5, act_type='lrelu', norm_type='BN'):\n",
    "        super().__init__()\n",
    "        inter_dim = int(in_dim * expand_ratio)\n",
    "        self.out_dim = out_dim\n",
    "        self.cv1 = Conv(in_dim, inter_dim, k=1, act_type=act_type, norm_type=norm_type)\n",
    "        self.cv2 = Conv(inter_dim * 4, out_dim, k=1, act_type=act_type, norm_type=norm_type)\n",
    "        self.m = nn.MaxPool2d(kernel_size=pooling_size, stride=1, padding=pooling_size // 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cv1(x)\n",
    "        y1 = self.m(x)\n",
    "        y2 = self.m(y1)\n",
    "\n",
    "        return self.cv2(torch.cat((x, y1, y2, self.m(y2)), 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 头部网络\n",
    "头部将输出是否有物体，类别，检测框和其偏移。\n",
    "值得注意的是，在检测头有两个输出，分别用于预测中心点的偏移、box的宽和高\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解偶检测头\n",
    "class DecoupledHead(nn.Module):\n",
    "    def __init__(self, cfg, in_dim, out_dim, num_classes=80):\n",
    "        super().__init__()\n",
    "        print('==============================')\n",
    "        print('Head: Decoupled Head')\n",
    "        self.in_dim = in_dim\n",
    "        self.num_cls_head=cfg['num_cls_head']\n",
    "        self.num_reg_head=cfg['num_reg_head']\n",
    "        self.act_type=cfg['head_act']\n",
    "        self.norm_type=cfg['head_norm']\n",
    "\n",
    "        # ------------------ 类别检测头 ------------------\n",
    "        cls_feats = []\n",
    "        self.cls_out_dim = max(out_dim, num_classes)\n",
    "        for i in range(cfg['num_cls_head']):\n",
    "            if i == 0:\n",
    "                cls_feats.append(\n",
    "                    Conv(in_dim, self.cls_out_dim, k=3, p=1, s=1, \n",
    "                        act_type=self.act_type,\n",
    "                        norm_type=self.norm_type,\n",
    "                        depthwise=cfg['head_depthwise'])\n",
    "                        )\n",
    "            else:\n",
    "                cls_feats.append(\n",
    "                    Conv(self.cls_out_dim, self.cls_out_dim, k=3, p=1, s=1, \n",
    "                        act_type=self.act_type,\n",
    "                        norm_type=self.norm_type,\n",
    "                        depthwise=cfg['head_depthwise'])\n",
    "                        )\n",
    "                \n",
    "        # ------------------ 回归检测头 ------------------\n",
    "        reg_feats = []\n",
    "        self.reg_out_dim = max(out_dim, 64)\n",
    "        for i in range(cfg['num_reg_head']):\n",
    "            if i == 0:\n",
    "                reg_feats.append(\n",
    "                    Conv(in_dim, self.reg_out_dim, k=3, p=1, s=1, \n",
    "                        act_type=self.act_type,\n",
    "                        norm_type=self.norm_type,\n",
    "                        depthwise=cfg['head_depthwise'])\n",
    "                        )\n",
    "            else:\n",
    "                reg_feats.append(\n",
    "                    Conv(self.reg_out_dim, self.reg_out_dim, k=3, p=1, s=1, \n",
    "                        act_type=self.act_type,\n",
    "                        norm_type=self.norm_type,\n",
    "                        depthwise=cfg['head_depthwise'])\n",
    "                        )\n",
    "        \n",
    "        self.cls_feats = nn.Sequential(*cls_feats)\n",
    "        self.reg_feats = nn.Sequential(*reg_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "            x: (torch.Tensor) [B, C, H, W]\n",
    "        \"\"\"\n",
    "        cls_feats = self.cls_feats(x)\n",
    "        reg_feats = self.reg_feats(x)\n",
    "\n",
    "        return cls_feats, reg_feats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 整体流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网络结构\n",
    "        # ------------------- 网络结构 -------------------\n",
    "        ## 主干网络\n",
    "        self.backbone, feat_dim = build_backbone(\n",
    "            cfg['backbone'], trainable&cfg['pretrained'])\n",
    "\n",
    "        ## 颈部网络\n",
    "        self.neck = build_neck(cfg, feat_dim, out_dim=512)\n",
    "        head_dim = self.neck.out_dim\n",
    "\n",
    "        ## 检测头\n",
    "        self.head = build_head(cfg, head_dim, head_dim, num_classes)\n",
    "\n",
    "        ## 预测层\n",
    "        # 一维，表示是否有obj\n",
    "        self.obj_pred = nn.Conv2d(head_dim, 1, kernel_size=1)\n",
    "        # 类别\n",
    "        self.cls_pred = nn.Conv2d(head_dim, num_classes, kernel_size=1)\n",
    "        # box预测\n",
    "        self.reg_pred = nn.Conv2d(head_dim, 4, kernel_size=1)\n",
    "\n",
    "# 训练\n",
    "    def forward(self, x):\n",
    "        if not self.trainable:\n",
    "            return self.inference(x)\n",
    "        else:\n",
    "            # 主干网络\n",
    "            feat = self.backbone(x)\n",
    "\n",
    "            # 颈部网络\n",
    "            feat = self.neck(feat)\n",
    "\n",
    "            # 检测头\n",
    "            cls_feat, reg_feat = self.head(feat)\n",
    "\n",
    "            # 预测层\n",
    "            # 是否含有物体\n",
    "            obj_pred = self.obj_pred(cls_feat)\n",
    "            # 类别预测\n",
    "            cls_pred = self.cls_pred(cls_feat)\n",
    "            # 边界预测\n",
    "            reg_pred = self.reg_pred(reg_feat)\n",
    "            # H和W\n",
    "            fmp_size = obj_pred.shape[-2:]\n",
    "\n",
    "            # 对 pred 的 size 做一些 view 调整，便于后续的处理\n",
    "            # [B, C, H, W] -> [B, H, W, C] -> [B, H*W, C]\n",
    "            obj_pred = obj_pred.permute(0, 2, 3, 1).contiguous().flatten(1, 2)\n",
    "            cls_pred = cls_pred.permute(0, 2, 3, 1).contiguous().flatten(1, 2)\n",
    "            reg_pred = reg_pred.permute(0, 2, 3, 1).contiguous().flatten(1, 2)\n",
    "\n",
    "            # 解算边界框坐标\n",
    "            box_pred = self.decode_boxes(reg_pred, fmp_size)\n",
    "\n",
    "            # 网络输出\n",
    "            outputs = {\"pred_obj\": obj_pred,        # (torch.Tensor) [B, M, 1]\n",
    "                       \"pred_cls\": cls_pred,        # (torch.Tensor) [B, M, C]\n",
    "                       \"pred_box\": box_pred,        # (torch.Tensor) [B, M, 4]\n",
    "                       \"stride\": self.stride,       # (Int)\n",
    "                       \"fmp_size\": fmp_size         # (List[int, int])\n",
    "                       }           \n",
    "            return outputs\n",
    "\n",
    "# 推理\n",
    "    @torch.no_grad()\n",
    "    def inference(self, x):\n",
    "        # 主干网络\n",
    "        feat = self.backbone(x)\n",
    "\n",
    "        # 颈部网络\n",
    "        feat = self.neck(feat)\n",
    "\n",
    "        # 检测头\n",
    "        cls_feat, reg_feat = self.head(feat)\n",
    "\n",
    "        # 预测层\n",
    "        obj_pred = self.obj_pred(cls_feat)\n",
    "        cls_pred = self.cls_pred(cls_feat)\n",
    "        reg_pred = self.reg_pred(reg_feat)\n",
    "        fmp_size = obj_pred.shape[-2:]\n",
    "\n",
    "        # 对 pred 的 size 做一些 view 调整，便于后续的处理\n",
    "        # [B, C, H, W] -> [B, H, W, C] -> [B, H*W, C]\n",
    "        obj_pred = obj_pred.permute(0, 2, 3, 1).contiguous().flatten(1, 2)\n",
    "        cls_pred = cls_pred.permute(0, 2, 3, 1).contiguous().flatten(1, 2)\n",
    "        reg_pred = reg_pred.permute(0, 2, 3, 1).contiguous().flatten(1, 2)\n",
    "\n",
    "        # 测试时，笔者默认 batch 是1，\n",
    "        # 因此，我们不需要用batch这个维度，用[0]将其取走。\n",
    "        obj_pred = obj_pred[0]       # [H*W, 1]\n",
    "        cls_pred = cls_pred[0]       # [H*W, NC]\n",
    "        reg_pred = reg_pred[0]       # [H*W, 4]\n",
    "\n",
    "        # 每个边界框的得分\n",
    "        scores = torch.sqrt(obj_pred.sigmoid() * cls_pred.sigmoid())\n",
    "        \n",
    "        # 解算边界框, 并归一化边界框: [H*W, 4]\n",
    "        bboxes = self.decode_boxes(reg_pred, fmp_size)\n",
    "        \n",
    "        if self.deploy:\n",
    "            # 这段代码和ONNX部署有关，读者不必关注这段if的代码\n",
    "            # [n_anchors_all, 4 + C]\n",
    "            outputs = torch.cat([bboxes, scores], dim=-1)\n",
    "\n",
    "            return outputs\n",
    "        else:\n",
    "            # 将 bbox 和 score 预测都放在 cpu 处理上，以便进行后处理\n",
    "            scores = scores.cpu().numpy()\n",
    "            bboxes = bboxes.cpu().numpy()\n",
    "            \n",
    "            # 后处理\n",
    "            # 在其他语言c++中，也需要做这步\n",
    "            bboxes, scores, labels = self.postprocess(bboxes, scores)\n",
    "\n",
    "        return bboxes, scores, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练\n",
    "1. 样本的制作，标注使用了box和类别，如何和神经网络的输出关联起来\n",
    "   - 样本制作只有正样本\n",
    "2. 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 样本数据匹配\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# YoloMatcher类用于完成训练阶段的<标签分配>\n",
    "class YoloMatcher(object):\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def __call__(self, fmp_size, stride, targets):\n",
    "        \"\"\"\n",
    "        输入参数的解释:\n",
    "            img_size: (Int) 输入图像的尺寸\n",
    "            stride:   (Int) YOLOv1网络的输出步长\n",
    "            targets:  (List[Dict]) 为List类型，包含一批数据的标签，每一个数据标签为Dict类型，其主要的数据结构为：\n",
    "                             dict{'boxes':  (torch.Tensor) [N, 4], 一张图像中的N个目标边界框坐标\n",
    "                                  'labels': (torch.Tensor) [N,], 一张图像中的N个目标类别标签\n",
    "                                  ...}\n",
    "        return\n",
    "        1. 是否有坐标\n",
    "        2. one hot 类别标签\n",
    "        3. 边界框标签 在原始图像中的坐标\n",
    "        \"\"\"\n",
    "        # 准备后续处理会用到的变量\n",
    "        bs = len(targets)\n",
    "        fmp_h, fmp_w = fmp_size\n",
    "        gt_objectness = np.zeros([bs, fmp_h, fmp_w, 1]) \n",
    "        # one hot\n",
    "        gt_classes = np.zeros([bs, fmp_h, fmp_w, self.num_classes]) \n",
    "        # 在原始图像中的坐标\n",
    "        gt_bboxes = np.zeros([bs, fmp_h, fmp_w, 4])\n",
    "\n",
    "        # 第一层for循环遍历每一张图像的标签\n",
    "        for batch_index in range(bs):\n",
    "            targets_per_image = targets[batch_index]\n",
    "            # [N,]\n",
    "            tgt_cls = targets_per_image[\"labels\"].numpy()\n",
    "            # [N, 4]\n",
    "            tgt_box = targets_per_image['boxes'].numpy()\n",
    "\n",
    "            # 第二层for循环遍历该张图像的每一个目标的标签\n",
    "            for gt_box, gt_label in zip(tgt_box, tgt_cls):\n",
    "                # 获得该目标的边界框坐标\n",
    "                x1, y1, x2, y2 = gt_box\n",
    "\n",
    "                # 计算目标框的中心点坐标和宽高\n",
    "                xc, yc = (x2 + x1) * 0.5, (y2 + y1) * 0.5\n",
    "                bw, bh = x2 - x1, y2 - y1\n",
    "\n",
    "                # 检查该目标边界框是否有效\n",
    "                if bw < 1. or bh < 1.:\n",
    "                    continue    \n",
    "\n",
    "                # 计算中心点所在的网格坐标\n",
    "                xs_c = xc / stride\n",
    "                ys_c = yc / stride\n",
    "                grid_x = int(xs_c)\n",
    "                grid_y = int(ys_c)\n",
    "\n",
    "                #  检查网格坐标是否有效\n",
    "                if grid_x < fmp_w and grid_y < fmp_h:\n",
    "                    # 标记objectness标签，即此处的网格有物体，对应一个正样本\n",
    "                    gt_objectness[batch_index, grid_y, grid_x] = 1.0\n",
    "\n",
    "                    # 标记正样本处的类别标签，采用one-hot格式\n",
    "                    cls_ont_hot = np.zeros(self.num_classes)\n",
    "                    cls_ont_hot[int(gt_label)] = 1.0\n",
    "                    gt_classes[batch_index, grid_y, grid_x] = cls_ont_hot\n",
    "\n",
    "                    # 标记正样本处的bbox标签\n",
    "                    gt_bboxes[batch_index, grid_y, grid_x] = np.array([x1, y1, x2, y2])\n",
    "\n",
    "        # 将标签数据的shape从 [B, H, W, C] 的形式reshape成 [B, M, C] ，其中M = HW，以便后续的处理\n",
    "        gt_objectness = gt_objectness.reshape(bs, -1, 1)\n",
    "        gt_classes = gt_classes.reshape(bs, -1, self.num_classes)\n",
    "        gt_bboxes = gt_bboxes.reshape(bs, -1, 4)\n",
    "\n",
    "        # 将numpy.array类型转换为torch.Tensor类型\n",
    "        gt_objectness = torch.from_numpy(gt_objectness).float()\n",
    "        gt_classes = torch.from_numpy(gt_classes).float()\n",
    "        gt_bboxes = torch.from_numpy(gt_bboxes).float()\n",
    "\n",
    "        return gt_objectness, gt_classes, gt_bboxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数\n",
    "# 3部分损失函数\n",
    "    def loss_objectness(self, pred_obj, gt_obj):\n",
    "        \"\"\"计算objectness损失\"\"\"\n",
    "        loss_obj = F.binary_cross_entropy_with_logits(pred_obj, gt_obj, reduction='none')\n",
    "\n",
    "        return loss_obj\n",
    "    \n",
    "    def loss_classes(self, pred_cls, gt_label):\n",
    "        \"\"\"计算classification损失\"\"\"\n",
    "        loss_cls = F.binary_cross_entropy_with_logits(pred_cls, gt_label, reduction='none')\n",
    "\n",
    "        return loss_cls\n",
    "\n",
    "    def loss_bboxes(self, pred_box, gt_box):\n",
    "        \"\"\"计算bbox regression损失\"\"\"\n",
    "        ious = get_ious(pred_box, gt_box, box_mode=\"xyxy\", iou_type='giou')\n",
    "        loss_box = 1.0 - ious\n",
    "\n",
    "# 将三部分相加为总损失，权重不同，权重属于超参数\n",
    "\n",
    "# 整体\n",
    "\n",
    "# Criterion类用于完成训练阶段的<标签分配>和<损失计算>两个重要环节\n",
    "class Criterion(object):\n",
    "    def __init__(self, cfg, device, num_classes=80):\n",
    "        self.cfg = cfg\n",
    "        self.device = device\n",
    "        self.num_classes = num_classes\n",
    "        self.loss_obj_weight = cfg['loss_obj_weight']\n",
    "        self.loss_cls_weight = cfg['loss_cls_weight']\n",
    "        self.loss_box_weight = cfg['loss_box_weight']\n",
    "\n",
    "        # 标签分配（制作正样本）\n",
    "        self.matcher = YoloMatcher(num_classes=num_classes)\n",
    "\n",
    "    def loss_objectness(self, pred_obj, gt_obj):\n",
    "        \"\"\"计算objectness损失\"\"\"\n",
    "        loss_obj = F.binary_cross_entropy_with_logits(pred_obj, gt_obj, reduction='none')\n",
    "\n",
    "        return loss_obj\n",
    "    \n",
    "    def loss_classes(self, pred_cls, gt_label):\n",
    "        \"\"\"计算classification损失\"\"\"\n",
    "        loss_cls = F.binary_cross_entropy_with_logits(pred_cls, gt_label, reduction='none')\n",
    "\n",
    "        return loss_cls\n",
    "\n",
    "    def loss_bboxes(self, pred_box, gt_box):\n",
    "        \"\"\"计算bbox regression损失\"\"\"\n",
    "        ious = get_ious(pred_box, gt_box, box_mode=\"xyxy\", iou_type='giou')\n",
    "        loss_box = 1.0 - ious\n",
    "\n",
    "        return loss_box\n",
    "\n",
    "    def __call__(self, outputs, targets, epoch=0):\n",
    "        device = outputs['pred_cls'][0].device\n",
    "        stride = outputs['stride']\n",
    "        fmp_size = outputs['fmp_size']\n",
    "        # List[B, M, C] -> [B, M, C] -> [BM, C]\n",
    "        pred_obj = outputs['pred_obj'].view(-1)                     # [BM,]\n",
    "        pred_cls = outputs['pred_cls'].view(-1, self.num_classes)   # [BM, C]\n",
    "        pred_box = outputs['pred_box'].view(-1, 4)                  # [BM, 4]\n",
    "       \n",
    "        # ------------------ 标签分配 ------------------\n",
    "        gt_objectness, gt_classes, gt_bboxes = self.matcher(fmp_size = fmp_size, \n",
    "                                                            stride   = stride, \n",
    "                                                            targets  = targets)\n",
    "        # 将标签的shape处理成和预测的shape相同的形式，以便后续计算损失\n",
    "        gt_objectness = gt_objectness.view(-1).to(device).float()               # [BM,]\n",
    "        gt_classes = gt_classes.view(-1, self.num_classes).to(device).float()   # [BM, C]\n",
    "        gt_bboxes = gt_bboxes.view(-1, 4).to(device).float()                    # [BM, 4]\n",
    "        # pos_mask: 正样本标记\n",
    "        pos_masks = (gt_objectness > 0)\n",
    "        # num_fgs: 正样本数量\n",
    "        num_fgs = pos_masks.sum()\n",
    "\n",
    "        # 如果使用多卡做分布式训练，需要在多张卡上计算正样本数量的均值\n",
    "        if is_dist_avail_and_initialized():\n",
    "            torch.distributed.all_reduce(num_fgs)\n",
    "        num_fgs = (num_fgs / get_world_size()).clamp(1.0)\n",
    "\n",
    "        # ------------------ 计算损失 ------------------\n",
    "        ## 计算objectness损失，即边界框的置信度、或有无物体的置信度的损失\n",
    "        loss_obj = self.loss_objectness(pred_obj, gt_objectness)\n",
    "        loss_obj = loss_obj.sum() / num_fgs\n",
    "\n",
    "        ## 计算classification损失，即类别的置信度的损失\n",
    "        pred_cls_pos = pred_cls[pos_masks]\n",
    "        gt_classes_pos = gt_classes[pos_masks]\n",
    "        loss_cls = self.loss_classes(pred_cls_pos, gt_classes_pos)\n",
    "        loss_cls = loss_cls.sum() / num_fgs\n",
    "\n",
    "        ## 计算box regression损失，即边界框回归的损失\n",
    "        pred_box_pos = pred_box[pos_masks]\n",
    "        gt_bboxes_pos = gt_bboxes[pos_masks]\n",
    "        loss_box = self.loss_bboxes(pred_box_pos, gt_bboxes_pos)\n",
    "        loss_box = loss_box.sum() / num_fgs\n",
    "        \n",
    "        ## 计算总的损失，即上面三个损失的加权和\n",
    "        losses = self.loss_obj_weight * loss_obj + \\\n",
    "                 self.loss_cls_weight * loss_cls + \\\n",
    "                 self.loss_box_weight * loss_box\n",
    "\n",
    "        ## 最后，将所有的loss保存在Dict中，以便后续的处理\n",
    "        loss_dict = dict(\n",
    "                loss_obj = loss_obj,\n",
    "                loss_cls = loss_cls,\n",
    "                loss_box = loss_box,\n",
    "                losses = losses\n",
    "        )\n",
    "\n",
    "        return loss_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 两个细节\n",
    "1. IOU计算实现\n",
    "2. 非极大值抑制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_ious(bboxes1,\n",
    "             bboxes2,\n",
    "             box_mode=\"xyxy\",\n",
    "             iou_type=\"iou\"):\n",
    "    \"\"\"\n",
    "    Compute iou loss of type ['iou', 'giou', 'linear_iou']\n",
    "\n",
    "    Args:\n",
    "        inputs (tensor): pred values\n",
    "        targets (tensor): target values\n",
    "        weight (tensor): loss weight\n",
    "        box_mode (str): 'xyxy' or 'ltrb', 'ltrb' is currently supported.\n",
    "        loss_type (str): 'giou' or 'iou' or 'linear_iou'\n",
    "        reduction (str): reduction manner\n",
    "\n",
    "    Returns:\n",
    "        loss (tensor): computed iou loss.\n",
    "    \"\"\"\n",
    "    if box_mode == \"ltrb\":\n",
    "        bboxes1 = torch.cat((-bboxes1[..., :2], bboxes1[..., 2:]), dim=-1)\n",
    "        bboxes2 = torch.cat((-bboxes2[..., :2], bboxes2[..., 2:]), dim=-1)\n",
    "    elif box_mode != \"xyxy\":\n",
    "        raise NotImplementedError\n",
    "\n",
    "    eps = torch.finfo(torch.float32).eps\n",
    "\n",
    "    bboxes1_area = (bboxes1[..., 2] - bboxes1[..., 0]).clamp_(min=0) \\\n",
    "        * (bboxes1[..., 3] - bboxes1[..., 1]).clamp_(min=0)\n",
    "    bboxes2_area = (bboxes2[..., 2] - bboxes2[..., 0]).clamp_(min=0) \\\n",
    "        * (bboxes2[..., 3] - bboxes2[..., 1]).clamp_(min=0)\n",
    "\n",
    "    w_intersect = (torch.min(bboxes1[..., 2], bboxes2[..., 2])\n",
    "                   - torch.max(bboxes1[..., 0], bboxes2[..., 0])).clamp_(min=0)\n",
    "    h_intersect = (torch.min(bboxes1[..., 3], bboxes2[..., 3])\n",
    "                   - torch.max(bboxes1[..., 1], bboxes2[..., 1])).clamp_(min=0)\n",
    "\n",
    "    area_intersect = w_intersect * h_intersect\n",
    "    area_union = bboxes2_area + bboxes1_area - area_intersect\n",
    "    ious = area_intersect / area_union.clamp(min=eps)\n",
    "\n",
    "    if iou_type == \"iou\":\n",
    "        return ious\n",
    "    elif iou_type == \"giou\":\n",
    "        g_w_intersect = torch.max(bboxes1[..., 2], bboxes2[..., 2]) \\\n",
    "            - torch.min(bboxes1[..., 0], bboxes2[..., 0])\n",
    "        g_h_intersect = torch.max(bboxes1[..., 3], bboxes2[..., 3]) \\\n",
    "            - torch.min(bboxes1[..., 1], bboxes2[..., 1])\n",
    "        ac_uion = g_w_intersect * g_h_intersect\n",
    "        gious = ious - (ac_uion - area_union) / ac_uion.clamp(min=eps)\n",
    "        return gious\n",
    "    else:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 非极大值抑制发生在推理后处理阶段\n",
    "\n",
    "## basic NMS\n",
    "def nms(bboxes, scores, nms_thresh):\n",
    "    \"\"\"\"Pure Python NMS.\"\"\"\n",
    "    x1 = bboxes[:, 0]  #xmin\n",
    "    y1 = bboxes[:, 1]  #ymin\n",
    "    x2 = bboxes[:, 2]  #xmax\n",
    "    y2 = bboxes[:, 3]  #ymax\n",
    "\n",
    "    areas = (x2 - x1) * (y2 - y1)\n",
    "    order = scores.argsort()[::-1]\n",
    "\n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "        # compute iou\n",
    "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "\n",
    "        w = np.maximum(1e-10, xx2 - xx1)\n",
    "        h = np.maximum(1e-10, yy2 - yy1)\n",
    "        inter = w * h\n",
    "\n",
    "        iou = inter / (areas[i] + areas[order[1:]] - inter + 1e-14)\n",
    "        #reserve all the boundingbox whose ovr less than thresh\n",
    "        # n2 = np.array([1,2,3])\n",
    "        # print(np.where(n2 > 1)) 二维 (array([1, 2], dtype=int64),)\n",
    "        inds = np.where(iou <= nms_thresh)[0]\n",
    "        # 这儿+1是因为iou从1开始计算\n",
    "        order = order[inds + 1]\n",
    "\n",
    "    return keep\n",
    "## class-agnostic NMS \n",
    "def multiclass_nms_class_agnostic(scores, labels, bboxes, nms_thresh):\n",
    "    # nms\n",
    "    keep = nms(bboxes, scores, nms_thresh)\n",
    "\n",
    "    scores = scores[keep]\n",
    "    labels = labels[keep]\n",
    "    bboxes = bboxes[keep]\n",
    "\n",
    "    return scores, labels, bboxes\n",
    "\n",
    "## class-aware NMS \n",
    "def multiclass_nms_class_aware(scores, labels, bboxes, nms_thresh, num_classes):\n",
    "    # nms\n",
    "    keep = np.zeros(len(bboxes), dtype=np.int32)\n",
    "    for i in range(num_classes):\n",
    "        inds = np.where(labels == i)[0]\n",
    "        if len(inds) == 0:\n",
    "            continue\n",
    "        c_bboxes = bboxes[inds]\n",
    "        c_scores = scores[inds]\n",
    "        c_keep = nms(c_bboxes, c_scores, nms_thresh)\n",
    "        keep[inds[c_keep]] = 1\n",
    "\n",
    "    keep = np.where(keep > 0)\n",
    "    scores = scores[keep]\n",
    "    labels = labels[keep]\n",
    "    bboxes = bboxes[keep]\n",
    "\n",
    "    return scores, labels, bboxes\n",
    "\n",
    "## multi-class NMS \n",
    "def multiclass_nms(scores, labels, bboxes, nms_thresh, num_classes, class_agnostic=False):\n",
    "    if class_agnostic:\n",
    "        return multiclass_nms_class_agnostic(scores, labels, bboxes, nms_thresh)\n",
    "    else:\n",
    "        return multiclass_nms_class_aware(scores, labels, bboxes, nms_thresh, num_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
